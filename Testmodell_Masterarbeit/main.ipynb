{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Masterarbeit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inhaltsverzeichnis\n",
    "\n",
    "1. Importstatements\n",
    "2. Datenvorbereitung\n",
    "3. Simulationsmodell\n",
    "4. Q-Learning-Agent\n",
    "5. Hyperparameters\n",
    "6. Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import statements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import multiprocessing\n",
    "import datetime\n",
    "from collections import deque\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model\n",
    "\n",
    "from tensorflow import summary, Variable, Session\n",
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.optimizers import RMSprop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datenvorbereitung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wetterdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_weather(path, start, ende):\n",
    "    df = pd.read_csv(\n",
    "        path, \n",
    "        index_col=\"date\", \n",
    "        memory_map=True\n",
    "\n",
    "        )\n",
    "    df = df.drop(columns=[\"Unnamed: 0\", \"HauptGruppe\", \"NebenGruppe\"])\n",
    "    # df = df.sort_index()\n",
    "    # df[\"Datum\"] = df.index.get_values()\n",
    "    # df[\"Datum\"] = pd.to_datetime(df[\"Datum\"]*24*3600, unit='s')\n",
    "    # df = df[df.Datum.dt.year.isin([2018,2019])]\n",
    "    # df = df[df.Datum.dt.dayofweek != 6]\n",
    "    df = df[df.index.isin(range(start, ende +3))]\n",
    "    # Plus 2 Tage, da Wetter von morgen und übermorgen\n",
    "    return df.to_numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preisdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_prices(path):\n",
    "    df = pd.read_csv(\n",
    "        path, \n",
    "        names=[\"Zeile\", \"Preis\",\"Artikelnummer\",\"Datum\"],\n",
    "        header=0,\n",
    "        index_col=\"Artikelnummer\", \n",
    "        memory_map=True\n",
    "        )\n",
    "    df = df.sort_index()\n",
    "    df = df.drop(columns=[\"Zeile\"])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Absatzdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sales(path):\n",
    "    # TODO: Statische Artikelinfo aus der Absatztabelle rausnehmen. (Warengruppe, Abteilung)\n",
    "    \"\"\"\n",
    "     for artikel in train_data[\"Artikel\"].unique():\n",
    "         warengruppen.append([artikel, train_data.loc[(slice(None), slice(5550,5550)),:].iloc[0].Warengruppe])\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(\n",
    "        path, \n",
    "        names=[\"Zeile\", \"Datum\", \"Artikel\", \"Absatz\", \"Warengruppe\", \"Abteilung\"], \n",
    "        header=0, \n",
    "        parse_dates=[1], \n",
    "        index_col=[1, 2],\n",
    "        memory_map=True\n",
    "        )\n",
    "    df.dropna(how='any', inplace=True)\n",
    "    df[\"Warengruppe\"] = df[\"Warengruppe\"].astype(np.uint8)\n",
    "    df = df.drop(columns=['Abteilung', 'Zeile'])\n",
    "    # Warengruppen auswählen\n",
    "    # 13 Frischmilch\n",
    "    # 14 Joghurt\n",
    "    # 69 Tabak\n",
    "    # 8 Obst Allgemen\n",
    "    # warengruppen = [8, 13, 14, 69 ]\n",
    "    warengruppen = [8]\n",
    "    df = df[df['Warengruppe'].isin(warengruppen)]\n",
    "    for i, wg in enumerate(warengruppen):\n",
    "        df.loc[df.Warengruppe == wg, \"Warengruppe\"] = i\n",
    "    df[\"Datum\"] = df.index.get_level_values('Datum')\n",
    "    df[\"Artikel\"] = df.index.get_level_values('Artikel').astype(np.int32)\n",
    "    # df[\"Wochentag\"] = df[\"Datum\"].apply(lambda x:x.dayofweek)\n",
    "    # df[\"Jahrestag\"] = df[\"Datum\"].apply(lambda x:x.dayofyear)\n",
    "    df[\"UNIXTag\"] = df[\"Datum\"].astype(np.int64)/(1000000000 * 24 * 3600)\n",
    "    df[\"Jahr\"] = df[\"Datum\"].apply(lambda x:x.year)\n",
    "    # df = df.drop(columns=['Datum'])\n",
    "    df = df.sort_index()\n",
    "    \n",
    "    test_data = df[df[\"Jahr\"]==2019]\n",
    "    train_data = df[df[\"Jahr\"]==2018]\n",
    "    return test_data, train_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_data_to_numpy(big_df, artikel, start, end):\n",
    "    \"\"\"Returns a numpy array with lenght = self.kalendertage. Days without Sales are filled with zeros\"\"\"\n",
    "    s = big_df[big_df.Artikel == artikel].copy()\n",
    "    s.set_index(s.UNIXTag, inplace=True)\n",
    "    wg = s.iloc[0][[\"Warengruppe\"]][0]\n",
    "    s = s.drop(columns=[\"Datum\", \"Artikel\", \"Warengruppe\", \"Jahr\", \"UNIXTag\"])\n",
    "    s = s.reindex(range(int(start), int(end+1)), fill_value=0)\n",
    "\n",
    "    return s.to_numpy(), wg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulationsmodell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockSimulation:\n",
    "    def __init__(self, data_dir, time_series_lenght):\n",
    "        \"\"\"\n",
    "        Lädt Daten selbstständig aus Data_dir und erstellt das Simulationsmodell. \n",
    "        1. Episode entspricht einem Durchlauf mit einem Artikel.\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        test_data, train_data = load_sales(os.path.join(data_dir, '3 absatz_altforweiler.csv'))\n",
    "\n",
    "        self.df = train_data\n",
    "\n",
    "        self.start_tag = int(min(train_data[\"UNIXTag\"]))\n",
    "        self.end_tag = int(max(train_data[\"UNIXTag\"]))\n",
    "        self.kalender_tage = self.end_tag - self.start_tag + 1\n",
    "\n",
    "        preise = load_prices(os.path.join(data_dir, '3 preise_altforweiler.csv'))\n",
    "\n",
    "        self.wetter = load_weather(os.path.join(data_dir, '2 wetter_saarlouis.csv'), self.start_tag, self.end_tag)\n",
    "        \n",
    "        self.warengruppen = self.df[\"Warengruppe\"].unique()\n",
    "        self.anz_wg = len(self.warengruppen)\n",
    "\n",
    "        self.anfangsbestand = np.random.randint(0,10)\n",
    "\n",
    "        self.time_series_lenght = time_series_lenght\n",
    "\n",
    "        olt = 1  # Fürs erste\n",
    "        self.fertig = None\n",
    "        self.vergangene_tage = None\n",
    "        self.akt_prod_bestand = None\n",
    "        self.akt_prod_absatz = None\n",
    "        self.akt_prod_wg = None\n",
    "        self.akt_prod_preis = None\n",
    "        self.akt_prod_olt = None\n",
    "        self.time_series_state = None\n",
    "\n",
    "        self.absatz_data = {}\n",
    "        self.static_state_data = {}\n",
    "        for artikel in tqdm(self.df[\"Artikel\"].unique()):\n",
    "            art_df, wg = copy_data_to_numpy(self.df, artikel, self.start_tag, self.end_tag)\n",
    "            self.absatz_data[artikel] = art_df\n",
    "            wg = to_categorical(wg, num_classes=self.anz_wg)\n",
    "\n",
    "            artikel_preis = preise.loc[artikel]\n",
    "\n",
    "            if type(artikel_preis) == pd.core.frame.DataFrame:\n",
    "                artikel_preis = np.array(\n",
    "                    [artikel_preis[artikel_preis.Datum == max(artikel_preis.Datum)][\"Preis\"].iat[0]]\n",
    "                )\n",
    "            elif type(artikel_preis) == pd.core.series.Series:\n",
    "                artikel_preis = np.array([artikel_preis[\"Preis\"]])\n",
    "            elif type(artikel_preis) == int:\n",
    "                artikel_preis = np.array([artikel_preis])\n",
    "            else:\n",
    "                raise AssertionError(\"Unknown Type for Price: {}\".format(type(artikel_preis)))\n",
    "            self.static_state_data[artikel] = {\"Warengruppe\":wg, \"OrderLeadTime\": olt, \"Preis\": artikel_preis}\n",
    "\n",
    "        self.aktueller_tag = self.start_tag\n",
    "        self.aktuelles_produkt = self.df[\"Artikel\"].sample(1).to_numpy()[0]\n",
    "\n",
    "    def create_new_state(self, wochentag):\n",
    "        new_state = np.concatenate(\n",
    "            [\n",
    "                np.array([self.akt_prod_bestand]), \n",
    "                wochentag, \n",
    "                self.akt_prod_wg, \n",
    "                self.akt_prod_preis, \n",
    "                self.wetter[self.vergangene_tage], \n",
    "                self.wetter[self.vergangene_tage+1]\n",
    "                ]\n",
    "            )\n",
    "        return new_state\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\" \n",
    "\n",
    "        \"\"\"\n",
    "        self.fertig = False\n",
    "        self.anfangsbestand = np.random.randint(0, 10)\n",
    "        self.aktueller_tag = self.start_tag\n",
    "        self.vergangene_tage = 0\n",
    "        self.aktuelles_produkt = self.df[\"Artikel\"].sample(1).to_numpy()[0]\n",
    "        self.akt_prod_bestand = self.anfangsbestand\n",
    "        self.akt_prod_absatz = self.absatz_data[self.aktuelles_produkt]\n",
    "        self.akt_prod_wg = self.static_state_data[self.aktuelles_produkt][\"Warengruppe\"]\n",
    "        self.akt_prod_preis = self.static_state_data[self.aktuelles_produkt][\"Preis\"]\n",
    "        self.akt_prod_olt = self.static_state_data[self.aktuelles_produkt][\"OrderLeadTime\"]\n",
    "\n",
    "        wochentag = self.aktueller_tag % 7\n",
    "\n",
    "        wochentag = to_categorical(wochentag, num_classes=7)\n",
    "\n",
    "        new_state = self.create_new_state(wochentag)\n",
    "        \n",
    "        self.time_series_state = deque(maxlen=self.time_series_lenght)\n",
    "        for _ in range(self.time_series_lenght):\n",
    "            self.time_series_state.append(new_state)\n",
    "        return np.array(self.time_series_state), {\"Artikel\": self.aktuelles_produkt}\n",
    "\n",
    "    def make_action(self, action):\n",
    "        if self.fertig:\n",
    "            raise AssertionError(\"Simulation für diesen Artikel fertig. Simulation zurücksetzen\")\n",
    "\n",
    "        absatz = self.akt_prod_absatz[self.vergangene_tage][0]\n",
    "\n",
    "        self.aktueller_tag += 1\n",
    "        self.vergangene_tage += 1\n",
    "\n",
    "        if self.aktueller_tag % 7 == 3: # Sonntag\n",
    "            self.aktueller_tag += 1\n",
    "            self.vergangene_tage += 1\n",
    "        \n",
    "        wochentag = self.aktueller_tag % 7\n",
    "\n",
    "        # Action ist die Bestellte Menge an Artikeln\n",
    "        # Tagsüber Absatz abziehen:\n",
    "        self.akt_prod_bestand -= absatz\n",
    "\n",
    "        # Nachmittag: Bestellung kommt an\n",
    "        self.akt_prod_bestand += action\n",
    "\n",
    "        # Abend: Bestand wird bewertet\n",
    "        if self.akt_prod_bestand >= 1:\n",
    "            reward = np.exp((-self.akt_prod_bestand+1)/5)\n",
    "        else:\n",
    "            reward = np.exp((self.akt_prod_bestand-1)*1.5-1)\n",
    "            # Nichtnegativität des Bestandes\n",
    "            self.akt_prod_bestand = 0\n",
    "\n",
    "        wochentag = to_categorical(wochentag, num_classes=7)\n",
    "        \n",
    "        new_state = self.create_new_state(wochentag)\n",
    "\n",
    "        self.time_series_state.append(new_state)\n",
    "\n",
    "        if self.vergangene_tage == self.kalender_tage -1:\n",
    "            self.fertig = True\n",
    "        \n",
    "        return reward, self.fertig, np.array(self.time_series_state)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Learning Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN:\n",
    "    def __init__(self, \n",
    "                 memory_size, \n",
    "                 state_shape, \n",
    "                 action_space, \n",
    "                 gamma, \n",
    "                 learning_rate, \n",
    "                 batch_size, \n",
    "                 epsilon, \n",
    "                 epsilon_decay, \n",
    "                 epsilon_min, \n",
    "                 possible_actions, \n",
    "                 time_series_length\n",
    "                 ):\n",
    "        self.memory_size = memory_size\n",
    "        self.state_shape = state_shape\n",
    "        self.action_space = action_space\n",
    "        self.gamma = gamma\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.epsilon = epsilon \n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.epsilon_min = epsilon_min\n",
    "        self.possible_actions = possible_actions\n",
    "        self.time_series_length = time_series_length\n",
    "        self.memory = deque(maxlen=memory_size)\n",
    "        self.model = self.create_model()\n",
    "        self.logdir = \"./logs/\" + datetime.datetime.today().date().__str__() + \"-\" \\\n",
    "                      + datetime.datetime.today().time().__str__()[:8].replace(\":\", \".\")\n",
    "        self.target_model = self.create_model()\n",
    "        self.sess = Session()\n",
    "        self.writer = summary.FileWriter(self.logdir, self.sess.graph)\n",
    "        self.reward = Variable(0.0, trainable=False, name=\"vReward\")\n",
    "        self.reward_mean = Variable(0.0, trainable=False, name=\"vMeanReward\")\n",
    "        self.loss = Variable(0.0, trainable=False, name=\"vLoss\")\n",
    "        self.accuracy = Variable(0.0, trainable=False, name=\"vMSE\")\n",
    "        self.summary_reward = summary.scalar(\"Reward\", self.reward)\n",
    "        self.summary_reward_mean = summary.scalar(\"MeanReward\", self.reward_mean)\n",
    "        self.summary_loss = summary.scalar(\"Loss\", self.loss)\n",
    "        self.summary_mse = summary.scalar(\"Accuracy\", self.accuracy)\n",
    "        self.merged = summary.merge(\n",
    "            [\n",
    "                self.summary_reward, \n",
    "                self.summary_reward_mean, \n",
    "                self.summary_loss, \n",
    "                self.summary_mse\n",
    "            ])\n",
    "\n",
    "    def create_model(self):\n",
    "        inputs = Input(shape=(self.time_series_length, self.state_shape))\n",
    "        x = LSTM(64, activation='relu')(inputs)\n",
    "        x = Dense(128, activation='relu')(x)\n",
    "        x = Dense(256, activation='relu')(x)\n",
    "        predictions = Dense(self.action_space, activation='relu')(x)\n",
    "        model = Model(inputs=inputs, outputs=predictions)\n",
    "        model.compile(optimizer=RMSprop(lr=self.learning_rate), loss='mse', metrics=[\"accuracy\"])\n",
    "        \n",
    "        return model\n",
    "\n",
    "    def remember(self, state, action, reward, new_state, done):\n",
    "        self.memory.append([state, action, reward, new_state, done])\n",
    "\n",
    "    def replay(self):\n",
    "        if len(self.memory) < self.batch_size:\n",
    "            return\n",
    "\n",
    "        samples = random.sample(self.memory, self.batch_size)\n",
    "\n",
    "        states = [sample[0] for sample in samples]\n",
    "        actions = [sample[1] for sample in samples]\n",
    "        rewards = [sample[2] for sample in samples]\n",
    "        new_states = [sample[3] for sample in samples]\n",
    "        new_states = np.array(new_states)\n",
    "        states = np.array(states)\n",
    "        dones = [sample[4] for sample in samples]\n",
    "        targets = self.target_model.predict(states)\n",
    "        qs_new_states = self.target_model.predict(new_states)\n",
    "        \n",
    "        target_qs_batch = []\n",
    "        for i in range(self.batch_size):\n",
    "            terminal = dones[i]\n",
    "\n",
    "            if terminal:\n",
    "                updated_target = targets[i]\n",
    "                updated_target[actions[i]] = rewards[i]\n",
    "                target_qs_batch.append(updated_target)\n",
    "            else:\n",
    "                updated_target = targets[i]\n",
    "                updated_target[actions[i]] = rewards[i] + self.gamma * np.max(qs_new_states[i])\n",
    "                target_qs_batch.append(updated_target)\n",
    "\n",
    "        targets = np.array([each for each in target_qs_batch])\n",
    "\n",
    "        history = self.model.fit(states, targets, epochs=1, verbose=0, callbacks=[])\n",
    "        return history.history\n",
    "\n",
    "    def target_train(self):\n",
    "        weights = self.model.get_weights()\n",
    "        target_weights = self.target_model.get_weights()\n",
    "        for i in range(len(target_weights)):\n",
    "            target_weights[i] = weights[i]\n",
    "        self.target_model.set_weights(target_weights)\n",
    "\n",
    "    def act(self, state):\n",
    "        self.epsilon *= self.epsilon_decay\n",
    "        self.epsilon = np.max([self.epsilon, self.epsilon_min])\n",
    "        if random.random() < self.epsilon:\n",
    "            return random.sample(self.possible_actions, 1)[0]\n",
    "        return np.argmax(self.model.predict(state.reshape(1, self.time_series_length, self.state_shape))[0])\n",
    "    \n",
    "    def save(self):\n",
    "        agent.target_model.save(\"model/model.h5\")\n",
    "    \n",
    "    def load(self):\n",
    "        model = load_model(\"model/model.h5\")\n",
    "        agent.target_model = model\n",
    "        agent.model = model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_train = True\n",
    "\n",
    "use_saved_model = False\n",
    "\n",
    "\n",
    "memory_size = 364*500\n",
    "gamma = 0.5\n",
    "epsilon = 1.0\n",
    "epsilon_min = 0.01\n",
    "epsilon_decay = 0.9999\n",
    "learning_rate = 0.0001\n",
    "tau = 0.05\n",
    "batch_size = 32\n",
    "n_step = 64\n",
    "log_frequency = 100  # jeder 100te n_step\n",
    "\n",
    "epochs = 10000\n",
    "\n",
    "update_target_network = batch_size * 100\n",
    "\n",
    "state_shape = 24\n",
    "action_space = 10\n",
    "\n",
    "time_series_length = 10\n",
    "\n",
    "order_none = 0\n",
    "order_one = 1\n",
    "order_two = 2\n",
    "order_tree = 3\n",
    "order_four = 4\n",
    "order_five = 5\n",
    "order_six = 6\n",
    "order_seven = 7\n",
    "order_eight = 8\n",
    "order_nine = 9\n",
    "\n",
    "possible_actions = [\n",
    "    order_none, \n",
    "    order_one, \n",
    "    order_two, \n",
    "    order_tree, \n",
    "    order_four, \n",
    "    order_five, \n",
    "    order_six, \n",
    "    order_seven, \n",
    "    order_eight, \n",
    "    order_nine\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainingsloop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialisieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'F:/OneDrive/Dokumente/1 Universität - Master/6. Semester/Masterarbeit/Implementation/Echtdaten'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dominic\\AppData\\Local\\conda\\conda\\envs\\masterarbeit\\lib\\site-packages\\numpy\\lib\\arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|                                                                                          | 0/566 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  2%|█▌                                                                              | 11/566 [00:00<00:05, 105.82it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  5%|███▋                                                                            | 26/566 [00:00<00:04, 115.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  7%|█████▉                                                                          | 42/566 [00:00<00:04, 125.68it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 11%|████████▍                                                                       | 60/566 [00:00<00:03, 136.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 14%|██████████▉                                                                     | 77/566 [00:00<00:03, 143.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 17%|█████████████▎                                                                  | 94/566 [00:00<00:03, 150.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 20%|███████████████▍                                                               | 111/566 [00:00<00:02, 154.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 23%|██████████████████                                                             | 129/566 [00:00<00:02, 160.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 26%|████████████████████▍                                                          | 146/566 [00:00<00:02, 160.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 29%|██████████████████████▉                                                        | 164/566 [00:01<00:02, 164.17it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 32%|█████████████████████████▎                                                     | 181/566 [00:01<00:02, 161.64it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 35%|███████████████████████████▋                                                   | 198/566 [00:01<00:02, 157.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 38%|█████████████████████████████▊                                                 | 214/566 [00:01<00:02, 152.19it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 41%|████████████████████████████████                                               | 230/566 [00:01<00:02, 153.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 43%|██████████████████████████████████▎                                            | 246/566 [00:01<00:02, 151.60it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 46%|████████████████████████████████████▌                                          | 262/566 [00:01<00:02, 150.54it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 49%|██████████████████████████████████████▊                                        | 278/566 [00:01<00:01, 150.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 52%|█████████████████████████████████████████                                      | 294/566 [00:01<00:01, 149.06it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 55%|███████████████████████████████████████████▏                                   | 309/566 [00:02<00:01, 148.45it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 58%|█████████████████████████████████████████████▌                                 | 326/566 [00:02<00:01, 152.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 61%|████████████████████████████████████████████████                               | 344/566 [00:02<00:01, 158.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 64%|██████████████████████████████████████████████████▌                            | 362/566 [00:02<00:01, 162.00it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 67%|████████████████████████████████████████████████████▉                          | 379/566 [00:02<00:01, 163.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 70%|███████████████████████████████████████████████████████▍                       | 397/566 [00:02<00:01, 166.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 73%|█████████████████████████████████████████████████████████▊                     | 414/566 [00:02<00:00, 165.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 76%|████████████████████████████████████████████████████████████▏                  | 431/566 [00:02<00:00, 166.98it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 79%|██████████████████████████████████████████████████████████████▋                | 449/566 [00:02<00:00, 168.29it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 83%|█████████████████████████████████████████████████████████████████▏             | 467/566 [00:02<00:00, 170.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 86%|███████████████████████████████████████████████████████████████████▋           | 485/566 [00:03<00:00, 170.44it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 89%|██████████████████████████████████████████████████████████████████████▏        | 503/566 [00:03<00:00, 171.68it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 92%|████████████████████████████████████████████████████████████████████████▋      | 521/566 [00:03<00:00, 172.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 95%|███████████████████████████████████████████████████████████████████████████▏   | 539/566 [00:03<00:00, 172.42it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 98%|█████████████████████████████████████████████████████████████████████████████▋ | 557/566 [00:03<00:00, 172.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r100%|███████████████████████████████████████████████████████████████████████████████| 566/566 [00:03<00:00, 161.21it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "simulation = StockSimulation(data_dir, time_series_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = DQN(\n",
    "    memory_size, \n",
    "    state_shape, \n",
    "    action_space, \n",
    "    gamma,\n",
    "    learning_rate, \n",
    "    batch_size, \n",
    "    epsilon, \n",
    "    epsilon_decay, \n",
    "    epsilon_min, \n",
    "    possible_actions, \n",
    "    time_series_length\n",
    "    )\n",
    "\n",
    "if use_saved_model:\n",
    "    agent.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Artikel': 185992}"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMean reward: 0.0008869737928586575 --- Total Reward: 0.2758488495790425 --- EXP-EXP: 0.9693771228828401"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Artikel': 5864}"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMean reward: 0.0016909270113323709 --- Total Reward: 0.5258783005243673 --- EXP-EXP: 0.9396920063686125"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Artikel': 129964}"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMean reward: 0.0004927519553902271 --- Total Reward: 0.15324585812636063 --- EXP-EXP: 0.9109159335296094"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Artikel': 129963}"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMean reward: 0.000831870110043643 --- Total Reward: 0.258711604223573 --- EXP-EXP: 0.883021066833069"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Artikel': 15421}"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMean reward: 0.000782594347554857 --- Total Reward: 0.24338684208956055 --- EXP-EXP: 0.8559804212115764"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Artikel': 129964}"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMean reward: 0.0010319960565446046 --- Total Reward: 0.320950773585372 --- EXP-EXP: 0.8297678379581195"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Artikel': 184659}"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMean reward: 0.00026758009456602445 --- Total Reward: 0.08321740941003361 --- EXP-EXP: 0.8043579594205564"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Artikel': 320875}"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMean reward: 0.0008054213384654146 --- Total Reward: 0.25048603626274396 --- EXP-EXP: 0.7797262044710112"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Artikel': 15314}"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMean reward: 0.021977670817865353 --- Total Reward: 6.835055624356125 --- EXP-EXP: 0.7558487447264656"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Artikel': 13117}"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMean reward: 0.0008644492507177353 --- Total Reward: 0.2688437169732157 --- EXP-EXP: 0.7327024814975474"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Artikel': 6972}"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMean reward: 0.001816893633808059 --- Total Reward: 0.5650539201143063 --- EXP-EXP: 0.71026502344321"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Artikel': 168673}"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMean reward: 0.0033433477060848516 --- Total Reward: 1.0397811365923888 --- EXP-EXP: 0.6885146649096918"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Artikel': 6972}"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMean reward: 0.0010229511978373353 --- Total Reward: 0.3181378225274113 --- EXP-EXP: 0.6674303649328001"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Artikel': 340511}"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMean reward: 0.0024288226795560167 --- Total Reward: 0.7553638533419212 --- EXP-EXP: 0.6469917268832013"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Artikel': 5558}"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMean reward: -0.025981307654387054 --- Total Reward: -8.080186680514373 --- EXP-EXP: 0.6271789787350371"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Artikel': 143245}"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMean reward: 0.002156005418855799 --- Total Reward: 0.6705176852641535 --- EXP-EXP: 0.6079729539387682"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Artikel': 225539}"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMean reward: 0.00030489234552811135 --- Total Reward: 0.09482151945924262 --- EXP-EXP: 0.5893550728797433"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Artikel': 6079}"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMean reward: 0.0016492684779439218 --- Total Reward: 0.5129224966405597 --- EXP-EXP: 0.5713073249045721"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Artikel': 153122}"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMean reward: 0.0008717613187380904 --- Total Reward: 0.2711177701275461 --- EXP-EXP: 0.5538122508978873"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Artikel': 13478}"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMean reward: -0.005256576923507733 --- Total Reward: -1.634795423210905 --- EXP-EXP: 0.5368529263926637"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Artikel': 6057}"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMean reward: 0.005731897589293268 --- Total Reward: 1.7826201502702066 --- EXP-EXP: 0.5204129451977533"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Artikel': 11598}"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMean reward: 0.0010900741021059362 --- Total Reward: 0.3390130457549462 --- EXP-EXP: 0.504476403526783"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Artikel': 171669}"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMean reward: 0.002522031393536097 --- Total Reward: 0.7843517633897262 --- EXP-EXP: 0.48902788461307556"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Artikel': 5906}"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMean reward: 0.0016755429551312542 --- Total Reward: 0.5210938590458201 --- EXP-EXP: 0.4740524437957048"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Artikel': 16193}"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMean reward: 0.002818954590506364 --- Total Reward: 0.8766948776474792 --- EXP-EXP: 0.4595355940622598"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Artikel': 5558}"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMean reward: -0.02295363874924512 --- Total Reward: -7.138581651015232 --- EXP-EXP: 0.4454632920343298"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Artikel': 13433}"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMean reward: 0.0010645492021376277 --- Total Reward: 0.3310748018648022 --- EXP-EXP: 0.4318219243821574"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Artikel': 320845}"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMean reward: 0.0009000784176934484 --- Total Reward: 0.27992438790266244 --- EXP-EXP: 0.4185982946553079"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Artikel': 308002}"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMean reward: 0.000744912245079173 --- Total Reward: 0.23166770821962282 --- EXP-EXP: 0.4057796105166253"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Artikel': 234598}"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMean reward: -0.03497453972477235 --- Total Reward: -10.877081854404201 --- EXP-EXP: 0.39335347136712556"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if do_train:\n",
    "    global_steps = 0\n",
    "    stats = {\"loss\": [], \"acc\": [], \"rew\": []}\n",
    "    for epoch in range(epochs):\n",
    "        state, info = simulation.reset()\n",
    "        print(info)\n",
    "        current_rewards = []\n",
    "        while True:\n",
    "            action = agent.act(state)\n",
    "            global_steps += 1\n",
    "            reward, fertig, new_state = simulation.make_action(action)\n",
    "            current_rewards.append(reward)\n",
    "            agent.remember(state, action, reward, new_state, fertig)\n",
    "            if global_steps % n_step == 0:\n",
    "                history = agent.replay()\n",
    "                if history:\n",
    "                    curr_loss = history[\"loss\"][0]\n",
    "                    curr_acc = history[\"acc\"][0]\n",
    "                    stats[\"loss\"].append(curr_loss)\n",
    "                    stats[\"acc\"].append(curr_acc)\n",
    "                \n",
    "            if global_steps % update_target_network == 0:\n",
    "                agent.target_train()\n",
    "    \n",
    "            state = new_state\n",
    "    \n",
    "            if fertig:\n",
    "                history = agent.replay()\n",
    "                curr_loss = history[\"loss\"][0]\n",
    "                curr_acc = history[\"acc\"][0]\n",
    "                curr_rew = np.sum(current_rewards)\n",
    "                curr_mean_rew = np.mean(current_rewards)\n",
    "                agent.sess.run(\n",
    "                    [\n",
    "                        agent.reward.assign(curr_rew), \n",
    "                        agent.reward_mean.assign(curr_mean_rew), \n",
    "                        agent.loss.assign(curr_loss), \n",
    "                        agent.accuracy.assign(curr_acc)\n",
    "                    ]\n",
    "                )\n",
    "                summary = agent.sess.run(agent.merged)\n",
    "                agent.writer.add_summary(summary, epoch)\n",
    "                print(\"Epoch {}\".format(epoch))\n",
    "                print(\n",
    "                    \"\\tMean reward: {} --- Total Reward: {} --- EXP-EXP: {}\".format(curr_mean_rew, curr_rew, agent.epsilon)\n",
    "                )\n",
    "                agent.save()\n",
    "                break\n",
    "    agent.writer.close()\n",
    "    agent.sess.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
